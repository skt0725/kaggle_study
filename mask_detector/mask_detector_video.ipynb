{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff9f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1fdbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "facenet = cv2.dnn.readNet('models/deploy.prototxt', 'models/res10_300x300_ssd_iter_140000.caffemodel')\n",
    "model = load_model('models/mask_detector.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43529d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('imgs/01.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    img = cv2.resize(img, (0,0), fx=0.3, fy=0.28)\n",
    "    h, w = img.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(img, scalefactor=1., size = (300, 300), mean = (104., 177., 123.))\n",
    "    facenet.setInput(blob)\n",
    "    dets = facenet.forward()\n",
    "    faces = []\n",
    "    face_point = []\n",
    "    for i in range (dets.shape[2]):\n",
    "        confidence = dets[0, 0, i, 2]\n",
    "        if confidence < 0.5:\n",
    "            continue\n",
    "\n",
    "        x1 = int(dets[0, 0, i, 3]*w)\n",
    "        y1 = int(dets[0, 0, i, 4]*h)\n",
    "        x2 = int(dets[0, 0, i, 5]*w)\n",
    "        y2 = int(dets[0, 0, i ,6]*h)\n",
    "\n",
    "        face = img[y1:y2, x1:x2]\n",
    "        faces.append(face)\n",
    "        face_point.append([x1, y1, x2, y2])\n",
    "        \n",
    "    for i, face in enumerate (faces):\n",
    "        face_input = cv2.resize(face, dsize=(224,224))\n",
    "        face_input = cv2.cvtColor(face_input, cv2.COLOR_BGR2RGB)\n",
    "        face_input = preprocess_input(face_input)\n",
    "        face_input = np.expand_dims(face_input, axis=0)\n",
    "\n",
    "        mask, nomask = model.predict(face_input).squeeze()\n",
    "        \n",
    "        img = cv2.rectangle(img, pt1=(face_point[i][0], face_point[i][1]), pt2=(face_point[i][2], face_point[i][3]), color=(255,255,255), thickness=1, lineType=cv2.LINE_AA)\n",
    "        if mask*100 < 90:\n",
    "            text_color = (0, 0, 255)\n",
    "            img = cv2.putText(img, 'no mask %.2f%%' % (mask * 100), (face_point[i][0], face_point[i][1]-5), cv2.FONT_HERSHEY_SIMPLEX, 0.3, text_color, thickness=1)\n",
    "        else:\n",
    "            text_color = (0, 255, 0)\n",
    "            img = cv2.putText(img, 'mask %.2f%%' % (mask * 100), (face_point[i][0], face_point[i][1]-5), cv2.FONT_HERSHEY_SIMPLEX, 0.3, text_color, thickness=1)\n",
    "        \n",
    "    cv2.imshow('img', img)\n",
    "    cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
